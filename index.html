<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AR Face Filter</title>
    
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
    
    <style>
        body {
            margin: 0;
            padding: 0;
            width: 100vw;
            height: 100vh;
            overflow: hidden;
            background: #000;
        }
        
        #webcam, #canvas {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            object-fit: cover;
        }
        
        #canvas {
            transform: scaleX(-1);
        }
        
        .status {
            position: fixed;
            top: 20px;
            left: 50%;
            transform: translateX(-50%);
            background: rgba(0, 0, 0, 0.7);
            color: white;
            padding: 10px 20px;
            border-radius: 20px;
            font-family: Arial, sans-serif;
            z-index: 1000;
        }
        
        #screenshot-btn {
            position: fixed;
            bottom: 20px;
            left: 50%;
            transform: translateX(-50%);
            padding: 10px 20px;
            background: #4CAF50;
            color: white;
            border: none;
            border-radius: 5px;
            cursor: pointer;
            font-size: 16px;
            z-index: 1000;
        }
        
        #screenshot-btn:hover {
            background: #45a049;
        }
        
        #file-input {
            display: none;
        }
        
        #upload-btn {
            position: fixed;
            bottom: 70px;
            left: 50%;
            transform: translateX(-50%);
            padding: 10px 20px;
            background: #2196F3;
            color: white;
            border: none;
            border-radius: 5px;
            cursor: pointer;
            font-size: 16px;
            z-index: 1000;
        }
        
        #upload-btn:hover {
            background: #1976D2;
        }
    </style>
</head>
<body>
    <video id="webcam" autoplay playsinline></video>
    <canvas id="canvas"></canvas>
    <div class="status">Loading...</div>
    <button id="screenshot-btn">Take Screenshot</button>
    <input type="file" id="file-input" accept="image/png,image/jpeg">
    <button id="upload-btn">Upload Face Image</button>
    
    <script>
        let faceMesh;
        let camera;
        let filterImage = null;
        
        function updateStatus(message) {
            const statusEl = document.querySelector('.status');
            if (statusEl) {
                statusEl.textContent = message;
            }
        }
        
        function takeScreenshot() {
            const canvas = document.getElementById('canvas');
            const link = document.createElement('a');
            link.download = 'face-filter-screenshot.png';
            link.href = canvas.toDataURL('image/png');
            link.click();
        }
        
        function handleFileUpload(event) {
            const file = event.target.files[0];
            if (file) {
                const reader = new FileReader();
                reader.onload = function(e) {
                    const img = new Image();
                    img.onload = function() {
                        filterImage = img;
                        updateStatus('Filter image loaded');
                    };
                    img.src = e.target.result;
                };
                reader.readAsDataURL(file);
            }
        }
        
        async function setupCamera() {
            const video = document.getElementById('webcam');
            
            try {
                const stream = await navigator.mediaDevices.getUserMedia({
                    video: {
                        width: { ideal: 1280 },
                        height: { ideal: 720 },
                        facingMode: 'user'
                    }
                });
                
                video.srcObject = stream;
                
                return new Promise((resolve) => {
                    video.onloadedmetadata = () => resolve(video);
                });
            } catch (error) {
                updateStatus('Camera access denied');
                throw error;
            }
        }
        
        function drawFilterImage(ctx, landmarks) {
            if (!filterImage) return;
            
            // Get face bounding box
            let minX = Infinity, minY = Infinity, maxX = -Infinity, maxY = -Infinity;
            landmarks.forEach(landmark => {
                minX = Math.min(minX, landmark.x * ctx.canvas.width);
                minY = Math.min(minY, landmark.y * ctx.canvas.height);
                maxX = Math.max(maxX, landmark.x * ctx.canvas.width);
                maxY = Math.max(maxY, landmark.y * ctx.canvas.height);
            });
            
            const faceWidth = maxX - minX;
            const faceHeight = maxY - minY;
            
            // Calculate scale to maintain aspect ratio
            const scale = Math.max(faceWidth / filterImage.width, faceHeight / filterImage.height);
            const scaledWidth = filterImage.width * scale;
            const scaledHeight = filterImage.height * scale;
            
            // Center the image on the face
            const centerX = (minX + maxX) / 2;
            const centerY = (minY + maxY) / 2;
            const x = centerX - scaledWidth / 2;
            const y = centerY - scaledHeight / 2;
            
            // Get rotation from eyes
            const leftEye = landmarks[33];
            const rightEye = landmarks[263];
            const angle = Math.atan2(
                rightEye.y * ctx.canvas.height - leftEye.y * ctx.canvas.height,
                rightEye.x * ctx.canvas.width - leftEye.x * ctx.canvas.width
            );
            
            // Draw the filter image with rotation
            ctx.save();
            ctx.translate(centerX, centerY);
            ctx.rotate(angle);
            ctx.translate(-centerX, -centerY);
            
            // Use face landmarks for perspective transform
            const sourcePoints = [
                [0, 0],
                [filterImage.width, 0],
                [filterImage.width, filterImage.height],
                [0, filterImage.height]
            ];
            
            const targetPoints = [
                [minX, minY],
                [maxX, minY],
                [maxX, maxY],
                [minX, maxY]
            ];
            
            // Draw the transformed image
            ctx.drawImage(filterImage, x, y, scaledWidth, scaledHeight);
            ctx.restore();
        }
        
        function onResults(results) {
            const canvas = document.getElementById('canvas');
            const ctx = canvas.getContext('2d');
            
            // Ensure canvas size matches video
            const video = document.getElementById('webcam');
            if (canvas.width !== video.videoWidth || canvas.height !== video.videoHeight) {
                canvas.width = video.videoWidth;
                canvas.height = video.videoHeight;
            }
            
            // Draw video frame
            ctx.save();
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            ctx.drawImage(results.image, 0, 0, canvas.width, canvas.height);
            
            // Apply filter if face detected
            if (results.multiFaceLandmarks && results.multiFaceLandmarks[0]) {
                drawFilterImage(ctx, results.multiFaceLandmarks[0]);
                updateStatus('Face tracked');
            }
            
            ctx.restore();
        }
        
        async function initFaceMesh() {
            try {
                faceMesh = new FaceMesh({
                    locateFile: (file) => {
                        return `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`;
                    }
                });
                
                faceMesh.setOptions({
                    maxNumFaces: 1,
                    refineLandmarks: true,
                    minDetectionConfidence: 0.5,
                    minTrackingConfidence: 0.5
                });
                
                faceMesh.onResults(onResults);
                
                const video = await setupCamera();
                camera = new Camera(video, {
                    onFrame: async () => {
                        await faceMesh.send({image: video});
                    },
                    width: 1280,
                    height: 720
                });
                
                await camera.start();
                updateStatus('Ready - Upload an image');
                
                // Setup buttons
                document.getElementById('screenshot-btn').addEventListener('click', takeScreenshot);
                document.getElementById('upload-btn').addEventListener('click', () => {
                    document.getElementById('file-input').click();
                });
                document.getElementById('file-input').addEventListener('change', handleFileUpload);
                
            } catch (error) {
                updateStatus('Error: Please refresh and try again');
                console.error(error);
            }
        }
        
        // Start everything when the page loads
        window.addEventListener('load', () => {
            if (window.location.protocol !== 'https:' && window.location.hostname !== 'localhost') {
                updateStatus('Error: HTTPS required');
                return;
            }
            
            initFaceMesh();
        });
    </script>
</body>
</html> 