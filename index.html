<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AR Face Detection</title>
    
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
    
    <style>
        body {
            margin: 0;
            padding: 0;
            width: 100vw;
            height: 100vh;
            overflow: hidden;
            background: #000;
        }
        
        #webcam, #canvas {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            object-fit: cover;
        }
        
        #canvas {
            transform: scaleX(-1);
        }
        
        .status {
            position: fixed;
            top: 20px;
            left: 50%;
            transform: translateX(-50%);
            background: rgba(0, 0, 0, 0.7);
            color: white;
            padding: 10px 20px;
            border-radius: 20px;
            font-family: Arial, sans-serif;
            z-index: 1000;
        }
    </style>
</head>
<body>
    <video id="webcam" autoplay playsinline style="display: none"></video>
    <canvas id="canvas"></canvas>
    <div class="status">Loading...</div>
    
    <script>
        let faceMesh;
        let camera;
        
        function updateStatus(message) {
            const statusEl = document.querySelector('.status');
            if (statusEl) {
                statusEl.textContent = message;
            }
        }
        
        async function setupCamera() {
            const video = document.getElementById('webcam');
            
            try {
                const stream = await navigator.mediaDevices.getUserMedia({
                    video: {
                        width: { ideal: 1280 },
                        height: { ideal: 720 },
                        facingMode: 'user'
                    }
                });
                
                video.srcObject = stream;
                
                return new Promise((resolve) => {
                    video.onloadedmetadata = () => resolve(video);
                });
            } catch (error) {
                updateStatus('Camera access denied');
                throw error;
            }
        }
        
        function onResults(results) {
            const canvas = document.getElementById('canvas');
            const ctx = canvas.getContext('2d');
            
            // Ensure canvas size matches video
            const video = document.getElementById('webcam');
            if (canvas.width !== video.videoWidth || canvas.height !== video.videoHeight) {
                canvas.width = video.videoWidth;
                canvas.height = video.videoHeight;
            }
            
            // Draw video frame
            ctx.save();
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            ctx.drawImage(results.image, 0, 0, canvas.width, canvas.height);
            
            // Draw face mesh if detected
            if (results.multiFaceLandmarks) {
                for (const landmarks of results.multiFaceLandmarks) {
                    ctx.fillStyle = '#00FF00';
                    for (const landmark of landmarks) {
                        const x = landmark.x * canvas.width;
                        const y = landmark.y * canvas.height;
                        ctx.beginPath();
                        ctx.arc(x, y, 2, 0, 2 * Math.PI);
                        ctx.fill();
                    }
                }
                updateStatus('Face detected');
            }
            
            ctx.restore();
        }
        
        async function initFaceMesh() {
            try {
                faceMesh = new FaceMesh({
                    locateFile: (file) => {
                        return `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`;
                    }
                });
                
                faceMesh.setOptions({
                    maxNumFaces: 1,
                    refineLandmarks: false,
                    minDetectionConfidence: 0.5,
                    minTrackingConfidence: 0.5
                });
                
                faceMesh.onResults(onResults);
                
                const video = await setupCamera();
                camera = new Camera(video, {
                    onFrame: async () => {
                        await faceMesh.send({image: video});
                    },
                    width: 1280,
                    height: 720
                });
                
                await camera.start();
                updateStatus('Ready');
                
            } catch (error) {
                updateStatus('Error: Please refresh and try again');
                console.error(error);
            }
        }
        
        // Start everything when the page loads
        window.addEventListener('load', () => {
            if (window.location.protocol !== 'https:' && window.location.hostname !== 'localhost') {
                updateStatus('Error: HTTPS required');
                return;
            }
            
            initFaceMesh();
        });
    </script>
</body>
</html> 