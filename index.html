<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AR Face Detection with 3D Model</title>
    
    <!-- MediaPipe -->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
    
    <!-- Three.js and required loaders -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/three@0.128.0/examples/js/loaders/GLTFLoader.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/three@0.128.0/examples/js/controls/OrbitControls.js"></script>
    
    <style>
        body {
            margin: 0;
            padding: 0;
            width: 100vw;
            height: 100vh;
            overflow: hidden;
            background: #000;
        }
        
        #webcam, #canvas, #three-canvas {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            object-fit: cover;
        }
        
        #three-canvas {
            pointer-events: none;
            z-index: 2;
        }
        
        #canvas {
            transform: scaleX(-1);
            z-index: 1;
        }
        
        .status {
            position: fixed;
            top: 20px;
            left: 50%;
            transform: translateX(-50%);
            background: rgba(0, 0, 0, 0.7);
            color: white;
            padding: 10px 20px;
            border-radius: 20px;
            font-family: Arial, sans-serif;
            z-index: 1000;
        }
        
        #screenshot-btn {
            position: fixed;
            bottom: 20px;
            left: 50%;
            transform: translateX(-50%);
            padding: 10px 20px;
            background: #4CAF50;
            color: white;
            border: none;
            border-radius: 5px;
            cursor: pointer;
            font-size: 16px;
            z-index: 1000;
        }
        
        #screenshot-btn:hover {
            background: #45a049;
        }
    </style>
</head>
<body>
    <video id="webcam" autoplay playsinline></video>
    <canvas id="canvas"></canvas>
    <canvas id="three-canvas"></canvas>
    <div class="status">Loading...</div>
    <button id="screenshot-btn">Take Screenshot</button>
    
    <script>
        let faceMesh;
        let camera;
        let scene;
        let renderer;
        let threeCamera;
        let faceModel;
        let isModelLoaded = false;
        
        function updateStatus(message) {
            const statusEl = document.querySelector('.status');
            if (statusEl) {
                statusEl.textContent = message;
            }
        }
        
        function takeScreenshot() {
            const canvas = document.getElementById('canvas');
            const threeCanvas = document.getElementById('three-canvas');
            
            // Create a temporary canvas to combine both layers
            const tempCanvas = document.createElement('canvas');
            tempCanvas.width = canvas.width;
            tempCanvas.height = canvas.height;
            const ctx = tempCanvas.getContext('2d');
            
            // Draw the face detection canvas
            ctx.drawImage(canvas, 0, 0);
            // Draw the Three.js canvas
            ctx.drawImage(threeCanvas, 0, 0);
            
            // Save the combined image
            const link = document.createElement('a');
            link.download = 'face-detection-3d.png';
            link.href = tempCanvas.toDataURL('image/png');
            link.click();
        }
        
        function initThreeJS() {
            // Set up Three.js scene
            scene = new THREE.Scene();
            
            // Set up camera
            const fov = 75;
            const aspect = window.innerWidth / window.innerHeight;
            threeCamera = new THREE.PerspectiveCamera(fov, aspect, 0.1, 1000);
            threeCamera.position.z = 5;
            
            // Set up renderer
            renderer = new THREE.WebGLRenderer({
                canvas: document.getElementById('three-canvas'),
                alpha: true
            });
            renderer.setSize(window.innerWidth, window.innerHeight);
            
            // Add lights
            const ambientLight = new THREE.AmbientLight(0xffffff, 0.5);
            scene.add(ambientLight);
            
            const directionalLight = new THREE.DirectionalLight(0xffffff, 0.8);
            directionalLight.position.set(0, 1, 1);
            scene.add(directionalLight);
            
            // Load 3D model
            const loader = new THREE.GLTFLoader();
            loader.load(
                'https://models.readyplayer.me/64c8c1d5c7fd7c0ebf11c116.glb',
                (gltf) => {
                    faceModel = gltf.scene;
                    // Adjust scale for this specific model
                    faceModel.scale.set(0.5, 0.5, 0.5);
                    // Center the model
                    faceModel.position.set(0, 0, 0);
                    scene.add(faceModel);
                    isModelLoaded = true;
                    updateStatus('3D Model loaded');
                },
                (progress) => {
                    const percent = (progress.loaded / progress.total * 100).toFixed(2);
                    updateStatus(`Loading 3D model: ${percent}%`);
                },
                (error) => {
                    console.error('Error loading model:', error);
                    updateStatus('Error loading 3D model. Retrying...');
                    // Fallback to a basic geometry if model fails
                    const geometry = new THREE.BoxGeometry(1, 1, 1);
                    const material = new THREE.MeshPhongMaterial({ color: 0x00ff00 });
                    faceModel = new THREE.Mesh(geometry, material);
                    scene.add(faceModel);
                    isModelLoaded = true;
                }
            );
        }
        
        async function setupCamera() {
            const video = document.getElementById('webcam');
            
            try {
                const stream = await navigator.mediaDevices.getUserMedia({
                    video: {
                        width: { ideal: 1280 },
                        height: { ideal: 720 },
                        facingMode: 'user'
                    }
                });
                
                video.srcObject = stream;
                
                return new Promise((resolve) => {
                    video.onloadedmetadata = () => resolve(video);
                });
            } catch (error) {
                updateStatus('Camera access denied');
                throw error;
            }
        }
        
        function updateFaceModel(landmarks) {
            if (!isModelLoaded || !faceModel) return;
            
            // Get key facial landmarks
            const nose = landmarks[4];
            const leftEye = landmarks[33];
            const rightEye = landmarks[263];
            
            // Update position
            faceModel.position.set(
                (nose.x - 0.5) * 10,
                -(nose.y - 0.5) * 10,
                -nose.z * 20
            );
            
            // Calculate rotation from landmarks
            const eyeVector = new THREE.Vector3(
                rightEye.x - leftEye.x,
                rightEye.y - leftEye.y,
                rightEye.z - leftEye.z
            );
            
            // Update rotation
            faceModel.rotation.y = Math.atan2(eyeVector.x, eyeVector.z);
            faceModel.rotation.z = Math.atan2(eyeVector.y, Math.sqrt(eyeVector.x * eyeVector.x + eyeVector.z * eyeVector.z));
            
            // Render the scene
            renderer.render(scene, threeCamera);
        }
        
        function onResults(results) {
            const canvas = document.getElementById('canvas');
            const ctx = canvas.getContext('2d');
            
            // Ensure canvas size matches video
            const video = document.getElementById('webcam');
            if (canvas.width !== video.videoWidth || canvas.height !== video.videoHeight) {
                canvas.width = video.videoWidth;
                canvas.height = video.videoHeight;
                
                // Update Three.js renderer size
                renderer.setSize(video.videoWidth, video.videoHeight);
                threeCamera.aspect = video.videoWidth / video.videoHeight;
                threeCamera.updateProjectionMatrix();
            }
            
            // Draw video frame
            ctx.save();
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            ctx.drawImage(results.image, 0, 0, canvas.width, canvas.height);
            
            // Update 3D model if face detected
            if (results.multiFaceLandmarks && results.multiFaceLandmarks[0]) {
                updateFaceModel(results.multiFaceLandmarks[0]);
                updateStatus('Face tracked');
            }
            
            ctx.restore();
        }
        
        async function initFaceMesh() {
            try {
                // Initialize Three.js
                initThreeJS();
                
                faceMesh = new FaceMesh({
                    locateFile: (file) => {
                        return `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`;
                    }
                });
                
                faceMesh.setOptions({
                    maxNumFaces: 1,
                    refineLandmarks: true,
                    minDetectionConfidence: 0.5,
                    minTrackingConfidence: 0.5
                });
                
                faceMesh.onResults(onResults);
                
                const video = await setupCamera();
                camera = new Camera(video, {
                    onFrame: async () => {
                        await faceMesh.send({image: video});
                    },
                    width: 1280,
                    height: 720
                });
                
                await camera.start();
                updateStatus('Ready');
                
                // Setup screenshot button
                document.getElementById('screenshot-btn').addEventListener('click', takeScreenshot);
                
            } catch (error) {
                updateStatus('Error: Please refresh and try again');
                console.error(error);
            }
        }
        
        // Handle window resize
        window.addEventListener('resize', () => {
            if (threeCamera && renderer) {
                const width = window.innerWidth;
                const height = window.innerHeight;
                
                threeCamera.aspect = width / height;
                threeCamera.updateProjectionMatrix();
                renderer.setSize(width, height);
            }
        });
        
        // Start everything when the page loads
        window.addEventListener('load', () => {
            if (window.location.protocol !== 'https:' && window.location.hostname !== 'localhost') {
                updateStatus('Error: HTTPS required');
                return;
            }
            
            initFaceMesh();
        });
    </script>
</body>
</html> 